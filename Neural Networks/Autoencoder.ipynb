{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\nimport numpy as np\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_data():\n    transform = transforms.Compose([transforms.ToTensor(),\n                                    transforms.Lambda(lambda x: x.view(-1))])\n\n    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\n    x_train = train_dataset.data.numpy().reshape(-1, 784) / 255.0\n    x_test = test_dataset.data.numpy().reshape(-1, 784) / 255.0\n    return x_train, x_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load data\nx_train, x_test = load_data()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Initialize weights and biases (Students need to implement)\n# Example: W1 = np.random.randn(512, 784) * 0.01\n# Hint: Use np.zeros for biases\n\n# 3. Define activation functions (Students need to implement)\n# def relu(x):\n#     return ...\n\n# def sigmoid(x):\n#     return ...\n\n# 4. Implement forward pass (Encoder + Decoder) - Students need to implement\n# def forward(x):\n#     # Encoder: multiple layers with ReLU activation\n#     # Decoder: multiple layers with ReLU/Sigmoid activation for reconstruction\n#     return z.T, x_reconstructed.T\n\n# 5. Compute Mean Squared Error Loss (Students need to implement)\n# def mse_loss(x, x_reconstructed):\n#     return ...\n\n# 6. Implement backpropagation and weight updates - Students need to implement\n# def backward(x, h1, h2, z, h3, h4, x_reconstructed, lr=0.001):\n#     # Compute gradients and update weights and biases\n#     pass\n\n# 7. Implement training loop - Students need to implement\n# def train(x_train, epochs=100, lr=0.001):\n#     # Train the network and collect loss and latent codes\n#     return losses, latent_codes, reconstructed_data\n\n# Train the model (Uncomment once students complete the train function)\n# losses, latent_codes, reconstructed_data = train(x_train)\n\n# 8. Plot the loss curve\ndef plot_loss_curve(losses):\n    plt.figure(figsize=(8, 6))\n    plt.plot(losses, label='MSE Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Loss Curve')\n    plt.legend()\n    plt.show()\n\n# Uncomment after training to plot the loss curve\n# plot_loss_curve(losses)\n\n# 9. Visualize latent codes using PCA\ndef visualize_latent_space(latent_codes):\n    pca = PCA(n_components=2)\n    reduced_codes = pca.fit_transform(latent_codes)\n    plt.figure(figsize=(8, 6))\n    plt.scatter(reduced_codes[:, 0], reduced_codes[:, 1], s=5, alpha=0.6)\n    plt.title('Latent Space Visualization (PCA)')\n    plt.xlabel('Component 1')\n    plt.ylabel('Component 2')\n    plt.show()\n\n# Uncomment after training to visualize latent space\n# visualize_latent_space(latent_codes)\n\n# 10. Show original and reconstructed images side by side\ndef show_images(original, reconstructed, n=10):\n    plt.figure(figsize=(20, 4))\n    for i in range(n):\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(original[i].reshape(28, 28), cmap='gray')\n        plt.axis('off')\n\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n        plt.axis('off')\n    plt.show()\n\n# Uncomment after training to show images\n# show_images(x_train, reconstructed_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}