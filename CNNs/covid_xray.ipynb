{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1503713,"sourceType":"datasetVersion","datasetId":884964}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torchvision import transforms \nfrom torch.utils.data import DataLoader\n\nfile_path = '/kaggle/input/covid19-chest-xray-image-dataset/dataset'\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)), \n    transforms.ToTensor(), \n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406], \n        std=[0.229, 0.224, 0.225])\n])\n\n# To use image folder, the data must be in the format\n# ├── dataset\n# │   ├── class1\n# |      ├── 1.jpg\n# │      ├── 2.jpg\n# │   ├── class2\n# |      ├── 1.jpg\n# │      ├── 2.jpg\n\nimage_dataset = ImageFolder(root=file_path, transform=transform)\ndata_loader = DataLoader(dataset=image_dataset, batch_size=32, shuffle=True) \n\nprint(f\"Classes: {image_dataset.classes}, {len(image_dataset.classes)} total\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T22:20:09.754440Z","iopub.execute_input":"2025-01-17T22:20:09.754961Z","iopub.status.idle":"2025-01-17T22:20:09.817907Z","shell.execute_reply.started":"2025-01-17T22:20:09.754926Z","shell.execute_reply":"2025-01-17T22:20:09.816553Z"}},"outputs":[{"name":"stdout","text":"Classes: ['covid', 'normal'], 2 total\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import torch.nn as nn \n\nclass CovidCNN(nn.Module): \n    def __init__(self): \n        self.conv_block = nn.Sequential(\n            nn.Conv2d(\n                in_channels=3, # it's prob only 1 \n                out_channels=16, \n                kernel_size=3, \n                padding=1, \n                stride=1\n            ), \n            nn.ReLU()\n            nn.Conv2d(\n                in_channels=16, \n                out_channels=32, \n                kernel_size=3, \n                padding=1, \n                stride=1\n            )\n            nn.ReLU()\n        )\n\n    def forward(self, x): \n        x = self.conv_block(x)\n\n        return x \n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}